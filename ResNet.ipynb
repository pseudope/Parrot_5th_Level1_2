{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMjcQW1TXYGGNu+SkExwWga",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pseudope/Parrot_5th_Level1_2/blob/main/ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYyZYbTOzRX7"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow.keras import Input, layers\n",
        "from tensorflow.keras.models import  Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, BatchNormalization, LeakyReLU, ReLU, PReLU\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import *\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import tensorflow_hub as hub\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDae4GyPz9zA"
      },
      "source": [
        "class Residual_Block(nn.Module):\n",
        "  def __init__(self, in_dim, mid_dim, out_dim):\n",
        "    super(Residual_Block, self).__init__()\n",
        "    self.residual_block = nn.Sequential(\n",
        "        nn.Conv2d(in_dim, mid_dim, kernel_size=3, padding=1),\n",
        "\n",
        "        nn.Conv2d(mid_dim, out_dim, kernel_size=3, padding=1),\n",
        "      )\n",
        "\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out = self.residual_block(x)\n",
        "    out = out + x\n",
        "    out = self.relu(out)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4J1VqBL0BRI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC_GJ-Y0zK0n"
      },
      "source": [
        "class ResNet50_layer4(nn.Module):\n",
        "    def __init__(self, num_classes= 10 ):\n",
        "        super(ResNet50_layer4, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 7, 2, 3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(3, 2, 1)\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            ResidualBlock(64, 64, 256, False),\n",
        "            ResidualBlock(256, 64, 256, False),\n",
        "            ResidualBlock(256, 64, 256, True)\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            ResidualBlock(256, 128, 512, False),\n",
        "            ResidualBlock(512, 128, 512, False),\n",
        "            ResidualBlock(512, 128, 512, False),\n",
        "            ResidualBlock(512, 128, 512, True)\n",
        "        )    \n",
        "        self.layer4 = nn.Sequential(\n",
        "            ResidualBlock(512, 256, 1024, False),\n",
        "            ResidualBlock(1024, 256, 1024, False),\n",
        "            ResidualBlock(1024, 256, 1024, False),\n",
        "            ResidualBlock(1024, 256, 1024, False),\n",
        "            ResidualBlock(1024, 256, 1024, False),\n",
        "            ResidualBlock(1024, 256, 1024, True)\n",
        "        )\n",
        "        self.layer5 = nn.Sequential(\n",
        "            ResidualBlock(1024, 512, 2048, False),\n",
        "            ResidualBlock(2048, 512, 2048, False),\n",
        "            ResidualBlock(2048, 512, 2048, False)\n",
        "        )\n",
        "        self.fc = nn.Linear(2048, 10)\n",
        "        self.avgpool = nn.AvgPool2d((2,2), stride=0)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        out = self.avgpool(out)\n",
        "        out = out.view(out.size()[0], -1)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3Y78DyPzWv1"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TQlGP_k0DWp"
      },
      "source": [
        "class ImageClassificationBase(nn.Module):\n",
        "  def trianing_steps(self, batch):\n",
        "    images, labels = batch\n",
        "    out = self(images)\n",
        "    loss = F.cross_entropy(out, lables)\n",
        "    return loss\n",
        "\n",
        "  def valdiation_step(self, batch):\n",
        "    images, labels = batch\n",
        "    out = self(images)\n",
        "    loss = F.cross_entropy(out, lables)\n",
        "    acc = accuracy(out, lables)\n",
        "    return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "  \n",
        "  def validation_epoch_end(self, outputs):\n",
        "    batch_losses = [x['val_loss'] for x in outputs]\n",
        "    epoch_loss = torch.stack(batch_losses).mean()\n",
        "    batch_accs = [x['val_acc'] for x in outputs]\n",
        "    epoch_acc = torch.stach(batch_accs),mean()\n",
        "    return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "\n",
        "  def epoch_end(self, epoch, result):\n",
        "    print(\"Eopch [{}], last_lr: {.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "        epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UdXAfvD0DB8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZwdvfmrzp9E"
      },
      "source": [
        "def conv_block(in_channels, out_channels, pool=False,p_size=2):\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
        "              nn.BatchNorm2d(out_channels), \n",
        "              nn.ReLU(inplace=True)]\n",
        "    if pool: layers.append(nn.MaxPool2d(p_size))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class ResNet9(ImageClassificationBase):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = conv_block(in_channels, 32)                             #32x150x150\n",
        "        self.conv2 = conv_block(32, 64, pool=True,p_size=4)                  #64x37x37\n",
        "        self.res1 = nn.Sequential(conv_block(64, 64), conv_block(64, 64))\n",
        "        \n",
        "        self.conv3 = conv_block(64, 128, pool=True,p_size=4)                 #128x9x9\n",
        "        self.conv4 = conv_block(128, 256, pool=True,p_size=4)                #256x2x2\n",
        "        self.res2 = nn.Sequential(conv_block(256, 256), conv_block(256, 256))\n",
        "        \n",
        "        self.classifier = nn.Sequential(nn.MaxPool2d(2),                     #256x1x1\n",
        "                                        nn.Flatten(), \n",
        "                                        nn.Linear(256, num_classes))\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        \n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "        out = self.res1(out) + out\n",
        "        \n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.res2(out) + out\n",
        "        \n",
        "        out = self.classifier(out)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBOtOzbBztcE"
      },
      "source": [
        "class Resnet34(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Use a pretrained model\n",
        "        self.network = models.resnet34(pretrained=True)\n",
        "        # Replace last layer\n",
        "        num_ftrs = self.network.fc.in_features\n",
        "        self.network.fc = nn.Linear(num_ftrs, 6)\n",
        "    \n",
        "    def forward(self, xb):\n",
        "        return torch.sigmoid(self.network(xb))\n",
        "    \n",
        "    def freeze(self):\n",
        "        # To freeze the residual layers\n",
        "        for param in self.network.parameters():\n",
        "            param.require_grad = False\n",
        "        for param in self.network.fc.parameters():\n",
        "            param.require_grad = True\n",
        "    \n",
        "    def unfreeze(self):\n",
        "        # Unfreeze all layers\n",
        "        for param in self.network.parameters():\n",
        "            param.require_grad = True"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6usvIgaazzFb"
      },
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n",
        "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
        "    torch.cuda.empty_cache()\n",
        "    history = []\n",
        "    \n",
        "    # Set up cutom optimizer with weight decay\n",
        "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
        "    # Set up one-cycle learning rate scheduler\n",
        "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n",
        "                                                steps_per_epoch=len(train_loader))\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        lrs = []\n",
        "        for batch in tqdm(train_loader):\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            \n",
        "            # Gradient clipping\n",
        "            if grad_clip: \n",
        "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "            \n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Record & update learning rate\n",
        "            lrs.append(get_lr(optimizer))\n",
        "            sched.step()\n",
        "        \n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        result['lrs'] = lrs\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcmJYETy15Bk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}